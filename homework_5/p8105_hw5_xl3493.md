Homework 5
================
Xuange Liang (xl3493)
2025-11-14

- [0.1 Problem 1: Birthday Paradox
  Simulation](#01-problem-1-birthday-paradox-simulation)
- [0.2 Problem 2: Power Analysis in One-Sample
  t-test](#02-problem-2-power-analysis-in-one-sample-t-test)
- [0.3 Problem 3: Homicide Data
  Analysis](#03-problem-3-homicide-data-analysis)

## 0.1 Problem 1: Birthday Paradox Simulation

### 0.1.1 Loading required libraries

``` r
library(tidyverse)
library(purrr)
set.seed(123)
```

### 0.1.2 Function to simulate birthday matching

``` r
# Function to check if at least two people share a birthday
simulate_birthday <- function(n) {
  # Generate n random birthdays (1-365)
  birthdays <- sample(1:365, size = n, replace = TRUE)

  # Check if there are any duplicates (implicit return)
  length(unique(birthdays)) < n
}

# Test the function
simulate_birthday(7)
```

    ## [1] FALSE

### 0.1.3 Running simulations for different group sizes

``` r
# Run 10000 simulations for each group size from 2 to 50

# Initialize results data frame
birthday_results <- data.frame(
  group_size = 2:50,
  probability = NA_real_
)

# Loop through each group size
for (i in seq_len(nrow(birthday_results))) {
  # Get current group size
  n <- birthday_results$group_size[i]

  # Run 10000 simulations for this group size
  simulations <- replicate(10000, simulate_birthday(n))

  # Calculate probability
  birthday_results$probability[i] <- mean(simulations)
}

# View results
head(birthday_results %>% select(group_size, probability), 10)
```

    ##    group_size probability
    ## 1           2      0.0032
    ## 2           3      0.0069
    ## 3           4      0.0147
    ## 4           5      0.0296
    ## 5           6      0.0387
    ## 6           7      0.0570
    ## 7           8      0.0758
    ## 8           9      0.0890
    ## 9          10      0.1143
    ## 10         11      0.1402

### 0.1.4 Visualization of results

``` r
# Plot probability vs group size
birthday_plot <- ggplot(birthday_results, aes(x = group_size, y = probability)) +
  geom_line(color = "steelblue", linewidth = 1.2) +
  geom_point(color = "steelblue", size = 2) +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "red") +
  geom_vline(xintercept = 23, linetype = "dashed", color = "red", alpha = 0.5) +
  labs(
    title = "Probability of Shared Birthday vs Group Size",
    subtitle = "Based on 10,000 simulations per group size",
    x = "Group Size (number of people)",
    y = "Probability of Shared Birthday"
  ) +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 10)
  )

birthday_plot
```

![](p8105_hw5_xl3493_files/figure-gfm/birthday_plot-1.png)<!-- -->

``` r
# Save plot
ggsave("results/birthday_paradox.png", birthday_plot, width = 10, height = 6)
```

**Comments on results:**

The simulation reveals the famous birthday paradox. The probability of a
shared birthday increases rapidly as group size grows. With just 23
people, there’s approximately a 50% chance of a shared birthday. By 50
people, the probability exceeds 95%, meaning it’s almost certain that at
least two people share a birthday.

------------------------------------------------------------------------

## 0.2 Problem 2: Power Analysis in One-Sample t-test

### 0.2.1 Setting up the simulation framework

``` r
library(broom)

# Simulation function for one-sample t-test
sim_t_test <- function(n = 30, mu = 0, sigma = 5) {
  # Generate data from Normal distribution
  data <- rnorm(n, mean = mu, sd = sigma)
  
  # Perform t-test against null hypothesis mu = 0
  t.test(data, mu = 0) %>%
    broom::tidy() %>%
    select(estimate, p.value)
}

# Test the function
sim_t_test(n = 30, mu = 0, sigma = 5)
```

    ## # A tibble: 1 × 2
    ##   estimate p.value
    ##      <dbl>   <dbl>
    ## 1   -0.658   0.511

### 0.2.2 Running simulations for μ = 0

``` r
# Run 5000 simulations for mu = 0
sim_results_mu0 <- 
  rerun(5000, sim_t_test(n = 30, mu = 0, sigma = 5)) %>%
  bind_rows()

# View first few results
head(sim_results_mu0)
```

    ## # A tibble: 6 × 2
    ##   estimate p.value
    ##      <dbl>   <dbl>
    ## 1   1.31    0.179 
    ## 2  -1.90    0.0262
    ## 3  -1.12    0.194 
    ## 4  -0.552   0.557 
    ## 5   0.0784  0.913 
    ## 6   0.994   0.248

``` r
# Summary statistics
sim_results_mu0 %>%
  summarize(
    mean_estimate = mean(estimate),
    mean_p_value = mean(p.value),
    rejection_rate = mean(p.value < 0.05)
  )
```

    ## # A tibble: 1 × 3
    ##   mean_estimate mean_p_value rejection_rate
    ##           <dbl>        <dbl>          <dbl>
    ## 1       0.00541        0.507          0.046

### 0.2.3 Running simulations for μ = {1, 2, 3, 4, 5, 6}

``` r
# Create function to run simulations for a given mu
run_sim_for_mu <- function(mu_value) {
  rerun(5000, sim_t_test(n = 30, mu = mu_value, sigma = 5)) %>%
    bind_rows()
}

# Run simulations for mu = 0, 1, 2, 3, 4, 5, 6
sim_results_all <- tibble(
  true_mu = 0:6
) %>%
  mutate(
    results = map(true_mu, run_sim_for_mu)
  ) %>%
  unnest(results)

# View structure
head(sim_results_all)
```

    ## # A tibble: 6 × 3
    ##   true_mu estimate p.value
    ##     <int>    <dbl>   <dbl>
    ## 1       0  -0.499    0.546
    ## 2       0   0.644    0.483
    ## 3       0  -0.895    0.341
    ## 4       0   0.0326   0.966
    ## 5       0  -1.15     0.215
    ## 6       0   0.102    0.913

### 0.2.4 Power analysis: Proportion of rejections vs effect size

``` r
# Calculate power for each true mu
power_results <- sim_results_all %>%
  group_by(true_mu) %>%
  summarize(
    power = mean(p.value < 0.05),
    n_simulations = n()
  )

# Create power plot
power_plot <- ggplot(power_results, aes(x = true_mu, y = power)) +
  geom_line(color = "darkblue", linewidth = 1.2) +
  geom_point(color = "darkblue", size = 3) +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "red", alpha = 0.5) +
  labs(
    title = "Power vs True Effect Size",
    subtitle = "One-sample t-test with n=30, σ=5, α=0.05",
    x = "True μ (Effect Size)",
    y = "Power (Proportion of Rejections)"
  ) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  scale_x_continuous(breaks = 0:6) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14)
  )

power_plot
```

![](p8105_hw5_xl3493_files/figure-gfm/power_plot-1.png)<!-- -->

``` r
# Save plot
ggsave("results/power_analysis.png", power_plot, width = 10, height = 6)
```

**Description of association between effect size and power:** - Power
increases monotonically with effect size. As the true μ moves further
from 0, we have greater ability to detect the effect. Power increases
rapidly from μ = 1 to μ = 3, then approaches 100% for larger effect
sizes. - When μ = 0 (null is true), the rejection rate is approximately
5%, matching our α = 0.05 significance level.

### 0.2.5 Average estimate of $\hat{\mu}$ analysis

``` r
# Calculate average estimates
estimate_results <- sim_results_all %>%
  group_by(true_mu) %>%
  summarize(
    avg_estimate_all = mean(estimate),
    avg_estimate_rejected = mean(estimate[p.value < 0.05]),
    n_total = n(),
    n_rejected = sum(p.value < 0.05)
  )

# View results
estimate_results
```

    ## # A tibble: 7 × 5
    ##   true_mu avg_estimate_all avg_estimate_rejected n_total n_rejected
    ##     <int>            <dbl>                 <dbl>   <int>      <int>
    ## 1       0          -0.0119               -0.0787    5000        266
    ## 2       1           0.992                 2.26      5000        899
    ## 3       2           2.00                  2.60      5000       2848
    ## 4       3           2.99                  3.18      5000       4436
    ## 5       4           3.99                  4.02      5000       4932
    ## 6       5           5.00                  5.00      5000       4998
    ## 7       6           5.99                  5.99      5000       5000

### 0.2.6 Plot: Average estimate vs true μ

``` r
# Prepare data for plotting
estimate_plot_data <- estimate_results %>%
  pivot_longer(
    cols = c(avg_estimate_all, avg_estimate_rejected),
    names_to = "sample_type",
    values_to = "avg_estimate",
    names_prefix = "avg_estimate_"
  ) %>%
  mutate(
    sample_type = factor(sample_type, 
                        levels = c("all", "rejected"),
                        labels = c("All samples", "Rejected samples only"))
  )

# Create plot
estimate_plot <- ggplot(estimate_plot_data, aes(x = true_mu, y = avg_estimate, 
                                                 color = sample_type)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", 
              color = "gray50", alpha = 0.5) +
  labs(
    title = "Average Estimate of $\\hat{\\mu}$ vs True μ",
    subtitle = "Comparing all samples vs samples where null was rejected",
    x = "True μ",
    y = "Average Estimate of μ̂",
    color = "Sample Type"
  ) +
  scale_x_continuous(breaks = 0:6) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    legend.position = "bottom"
  )

estimate_plot
```

![](p8105_hw5_xl3493_files/figure-gfm/estimate_plot-1.png)<!-- -->

``` r
# Save plot
ggsave("results/estimate_comparison.png", estimate_plot, width = 10, height = 6)
```

**Analysis: Is the sample average of $\hat{\mu}$(rejected only) ≈ true
μ?**

The sample average of $\hat{\mu}$across tests where the null is rejected
is **not** approximately equal to the true μ, especially for small
effect sizes. Here’s why:

- **Selection bias**: When we condition on rejection (p \< 0.05), we
  select samples where the test statistic was extreme enough to reject.
  This creates an upward bias in the estimates. The bias is most
  pronounced when true μ is small (1-2), where power is low. Only the
  most extreme estimates lead to rejection, pulling the average upward.

- **Diminishing bias**: As true μ increases and power approaches 100%,
  nearly all samples are rejected, so the average of rejected samples
  converges to the true μ. When true μ is 0, the average estimate of
  rejected samples falls close to 0 as there are very few rejections.

This illustrates the danger of publication bias: if only significant
results are published, the reported effect sizes will be systematically
inflated, leading to fallsacious conclusions.

------------------------------------------------------------------------

## 0.3 Problem 3: Homicide Data Analysis

### 0.3.1 Loading and describing the data

``` r
# Load data from Washington Post GitHub repository
homicide_data <- read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")

# View structure
head(homicide_data)
```

    ## # A tibble: 6 × 12
    ##   uid   reported_date victim_last victim_first victim_race victim_age victim_sex
    ##   <chr>         <dbl> <chr>       <chr>        <chr>       <chr>      <chr>     
    ## 1 Alb-…      20100504 GARCIA      JUAN         Hispanic    78         Male      
    ## 2 Alb-…      20100216 MONTOYA     CAMERON      Hispanic    17         Male      
    ## 3 Alb-…      20100601 SATTERFIELD VIVIANA      White       15         Female    
    ## 4 Alb-…      20100101 MENDIOLA    CARLOS       Hispanic    32         Male      
    ## 5 Alb-…      20100102 MULA        VIVIAN       White       72         Female    
    ## 6 Alb-…      20100126 BOOK        GERALDINE    White       91         Female    
    ## # ℹ 5 more variables: city <chr>, state <chr>, lat <dbl>, lon <dbl>,
    ## #   disposition <chr>

``` r
str(homicide_data)
```

    ## spc_tbl_ [52,179 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
    ##  $ uid          : chr [1:52179] "Alb-000001" "Alb-000002" "Alb-000003" "Alb-000004" ...
    ##  $ reported_date: num [1:52179] 20100504 20100216 20100601 20100101 20100102 ...
    ##  $ victim_last  : chr [1:52179] "GARCIA" "MONTOYA" "SATTERFIELD" "MENDIOLA" ...
    ##  $ victim_first : chr [1:52179] "JUAN" "CAMERON" "VIVIANA" "CARLOS" ...
    ##  $ victim_race  : chr [1:52179] "Hispanic" "Hispanic" "White" "Hispanic" ...
    ##  $ victim_age   : chr [1:52179] "78" "17" "15" "32" ...
    ##  $ victim_sex   : chr [1:52179] "Male" "Male" "Female" "Male" ...
    ##  $ city         : chr [1:52179] "Albuquerque" "Albuquerque" "Albuquerque" "Albuquerque" ...
    ##  $ state        : chr [1:52179] "NM" "NM" "NM" "NM" ...
    ##  $ lat          : num [1:52179] 35.1 35.1 35.1 35.1 35.1 ...
    ##  $ lon          : num [1:52179] -107 -107 -107 -107 -107 ...
    ##  $ disposition  : chr [1:52179] "Closed without arrest" "Closed by arrest" "Closed without arrest" "Closed by arrest" ...
    ##  - attr(*, "spec")=
    ##   .. cols(
    ##   ..   uid = col_character(),
    ##   ..   reported_date = col_double(),
    ##   ..   victim_last = col_character(),
    ##   ..   victim_first = col_character(),
    ##   ..   victim_race = col_character(),
    ##   ..   victim_age = col_character(),
    ##   ..   victim_sex = col_character(),
    ##   ..   city = col_character(),
    ##   ..   state = col_character(),
    ##   ..   lat = col_double(),
    ##   ..   lon = col_double(),
    ##   ..   disposition = col_character()
    ##   .. )
    ##  - attr(*, "problems")=<externalptr>

**Description of raw data:**

The Washington Post homicide dataset contains 52179 observations and 12
variables. The data tracks homicides in 50 large U.S. cities from 2007
to 2017.

Key variables include:

- `uid`: Unique identifier for each case
- `reported_date`: Date the homicide was reported
- `victim_last`, `victim_first`: Victim’s name
- `victim_race`, `victim_age`, `victim_sex`: Victim demographics
- `city`, `state`: Location of homicide
- `lat`, `lon`: Geographic coordinates
- `disposition`: Case outcome (Closed by arrest, Closed without arrest,
  Open/No arrest)

### 0.3.2 Creating city_state variable and summarizing homicides

``` r
# Create city_state and summarize
homicide_summary <- homicide_data %>%
  mutate(
    city_state = str_c(city, state, sep = ", ")
  ) %>%
  group_by(city_state) %>%
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest")),
    .groups = "drop"
  ) %>%
  arrange(desc(total_homicides))

# View summary
head(homicide_summary, 10)
```

    ## # A tibble: 10 × 3
    ##    city_state       total_homicides unsolved_homicides
    ##    <chr>                      <int>              <int>
    ##  1 Chicago, IL                 5535               4073
    ##  2 Philadelphia, PA            3037               1360
    ##  3 Houston, TX                 2942               1493
    ##  4 Baltimore, MD               2827               1825
    ##  5 Detroit, MI                 2519               1482
    ##  6 Los Angeles, CA             2257               1106
    ##  7 St. Louis, MO               1677                905
    ##  8 Dallas, TX                  1567                754
    ##  9 Memphis, TN                 1514                483
    ## 10 New Orleans, LA             1434                930

``` r
# Create table
knitr::kable(head(homicide_summary, 10), 
             caption = "Total and Unsolved Homicides by City (Top 10)")
```

| city_state       | total_homicides | unsolved_homicides |
|:-----------------|----------------:|-------------------:|
| Chicago, IL      |            5535 |               4073 |
| Philadelphia, PA |            3037 |               1360 |
| Houston, TX      |            2942 |               1493 |
| Baltimore, MD    |            2827 |               1825 |
| Detroit, MI      |            2519 |               1482 |
| Los Angeles, CA  |            2257 |               1106 |
| St. Louis, MO    |            1677 |                905 |
| Dallas, TX       |            1567 |                754 |
| Memphis, TN      |            1514 |                483 |
| New Orleans, LA  |            1434 |                930 |

Total and Unsolved Homicides by City (Top 10)

### 0.3.3 Proportion test for Baltimore, MD

``` r
# Filter Baltimore data
baltimore_data <- homicide_summary %>%
  filter(city_state == "Baltimore, MD")

# Perform proportion test
baltimore_test <- prop.test(
  x = baltimore_data$unsolved_homicides,
  n = baltimore_data$total_homicides
) 

# Tidy the results
baltimore_tidy <- baltimore_test %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high)

baltimore_tidy
```

    ## # A tibble: 1 × 3
    ##   estimate conf.low conf.high
    ##      <dbl>    <dbl>     <dbl>
    ## 1    0.646    0.628     0.663

``` r
# Extract values
baltimore_prop <- baltimore_tidy$estimate
baltimore_ci_low <- baltimore_tidy$conf.low
baltimore_ci_high <- baltimore_tidy$conf.high
```

In Baltimore, MD, the estimated proportion of unsolved homicides is
**0.646** (95% CI: $$0.628, 0.663$$).

### 0.3.4 Proportion tests for all cities

``` r
# Function to perform prop.test and extract results
prop_test_tidy <- function(unsolved, total) {
  # Handle edge cases (early return needed here)
  if (total == 0 || is.na(unsolved) || is.na(total)) {
    return(tibble(estimate = NA, conf.low = NA, conf.high = NA))
  }
  
  # Perform test and tidy results (implicit return)
  prop.test(x = unsolved, n = total) %>%
    broom::tidy() %>%
    select(estimate, conf.low, conf.high)
}

# Run prop.test for all cities using tidy pipeline
all_cities_results <- homicide_summary %>%
  mutate(
    test_results = map2(unsolved_homicides, total_homicides, prop_test_tidy)
  ) %>%
  unnest(test_results)

# View results
head(all_cities_results)
```

    ## # A tibble: 6 × 6
    ##   city_state      total_homicides unsolved_homicides estimate conf.low conf.high
    ##   <chr>                     <int>              <int>    <dbl>    <dbl>     <dbl>
    ## 1 Chicago, IL                5535               4073    0.736    0.724     0.747
    ## 2 Philadelphia, …            3037               1360    0.448    0.430     0.466
    ## 3 Houston, TX                2942               1493    0.507    0.489     0.526
    ## 4 Baltimore, MD              2827               1825    0.646    0.628     0.663
    ## 5 Detroit, MI                2519               1482    0.588    0.569     0.608
    ## 6 Los Angeles, CA            2257               1106    0.490    0.469     0.511

### 0.3.5 Plot: Estimates and confidence intervals by city

``` r
# Create plot with error bars
homicide_plot <- all_cities_results %>%
  mutate(
    city_state = fct_reorder(city_state, estimate)
  ) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point(color = "steelblue", size = 2) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                width = 0.3, color = "steelblue", alpha = 0.6) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    subtitle = "Error bars represent 95% confidence intervals",
    x = "City, State",
    y = "Proportion of Unsolved Homicides"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    axis.text.y = element_text(size = 8)
  )

homicide_plot
```

![](p8105_hw5_xl3493_files/figure-gfm/homicide_plot-1.png)<!-- -->

``` r
# Save plot
ggsave("results/unsolved_homicides_by_city.png", 
       homicide_plot, 
       width = 10, 
       height = 12)
```

**Interpretation:**

The plot reveals substantial variation in unsolved homicide rates across
U.S. cities:

1.  **Highest rates**: Chicago, IL and New Orleans, LA have the highest
    proportions of unsolved homicides (around 0.70-0.74), meaning
    approximately 3 out of 4 homicides remain unsolved.

2.  **Lowest rates**: Cities like Richmond, VA and Charlotte, NC have
    much lower proportions (around 0.26-0.28), with most cases resulting
    in arrests.

3.  **Regional patterns**: There appear to be geographic and demographic
    patterns, with some major cities struggling with high unsolved
    rates.

4.  **Confidence intervals**: Larger cities tend to have narrower
    confidence intervals due to larger sample sizes, while smaller
    cities show more uncertainty.

------------------------------------------------------------------------
